{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":8094053,"datasetId":4611404,"databundleVersionId":8210886,"isSourceIdPinned":false}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2025-12-12T10:02:41.910992Z","iopub.execute_input":"2025-12-12T10:02:41.911771Z","iopub.status.idle":"2025-12-12T10:02:41.916083Z","shell.execute_reply.started":"2025-12-12T10:02:41.911743Z","shell.execute_reply":"2025-12-12T10:02:41.915309Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"kushagra3204/wheat-plant-diseases\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"execution":{"iopub.status.busy":"2025-12-12T10:02:41.917414Z","iopub.execute_input":"2025-12-12T10:02:41.917621Z","iopub.status.idle":"2025-12-12T10:02:42.072379Z","shell.execute_reply.started":"2025-12-12T10:02:41.917606Z","shell.execute_reply":"2025-12-12T10:02:42.071654Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/wheat-plant-diseases\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2025-12-12T10:02:42.073118Z","iopub.execute_input":"2025-12-12T10:02:42.073372Z","iopub.status.idle":"2025-12-12T10:02:42.079726Z","shell.execute_reply.started":"2025-12-12T10:02:42.073348Z","shell.execute_reply":"2025-12-12T10:02:42.079088Z"},"trusted":true},"outputs":[],"execution_count":38},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/wheat-plant-diseases/wheat-plant-diseases/'\nDATA_DIR_TRAIN = '/kaggle/input/wheat-plant-diseases/data/train'\nDATA_DIR_TEST = '/kaggle/input/wheat-plant-diseases/data/test'\nIMAGE_SIZE = (224, 224)\nBATCH_SIZE = 32\nEPOCHS = 30  \nNUM_CLASSES = 5","metadata":{"execution":{"iopub.status.busy":"2025-12-12T10:02:42.081788Z","iopub.execute_input":"2025-12-12T10:02:42.082061Z","iopub.status.idle":"2025-12-12T10:02:42.089473Z","shell.execute_reply.started":"2025-12-12T10:02:42.082044Z","shell.execute_reply":"2025-12-12T10:02:42.088688Z"},"trusted":true},"outputs":[],"execution_count":39},{"cell_type":"code","source":"TRAIN_CLASS_FOLDERS = ['Aphid', 'Blast', 'Mildew', 'Smut', 'Tan spot']\nTEST_CLASS_FOLDERS = ['aphid_test', 'blast_test', 'mildew_test', 'smut_test', 'tan_spot_test']\nREPORT_TARGET_CLASSES = ['Aphid', 'Wheat Blast', 'Powdery Mildew', 'Smut', 'Spot Blotch']","metadata":{"execution":{"iopub.status.busy":"2025-12-12T10:02:42.090091Z","iopub.execute_input":"2025-12-12T10:02:42.090271Z","iopub.status.idle":"2025-12-12T10:02:42.100207Z","shell.execute_reply.started":"2025-12-12T10:02:42.090257Z","shell.execute_reply":"2025-12-12T10:02:42.099577Z"},"trusted":true},"outputs":[],"execution_count":40},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,        \n    zoom_range=0.2,         \n    horizontal_flip=True,\n    fill_mode='nearest',\n    validation_split=0.2\n)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)","metadata":{"execution":{"iopub.status.busy":"2025-12-12T10:02:42.100884Z","iopub.execute_input":"2025-12-12T10:02:42.101211Z","iopub.status.idle":"2025-12-12T10:02:42.113606Z","shell.execute_reply.started":"2025-12-12T10:02:42.101179Z","shell.execute_reply":"2025-12-12T10:02:42.112843Z"},"trusted":true},"outputs":[],"execution_count":41},{"cell_type":"code","source":"print(\"--- Initializing Data Generators ---\")\n\n# TRAINING GENERATOR\ntrain_generator = train_datagen.flow_from_directory(\n    DATA_DIR_TRAIN, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n    classes=TRAIN_CLASS_FOLDERS, class_mode='categorical', subset='training', shuffle=True\n)\n\n# VALIDATION GENERATOR\nvalidation_generator = train_datagen.flow_from_directory(\n    DATA_DIR_TRAIN, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n    classes=TRAIN_CLASS_FOLDERS, class_mode='categorical', subset='validation', shuffle=False\n)\n\n# TEST GENERATOR\ntest_generator = test_datagen.flow_from_directory(\n    DATA_DIR_TEST, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n    classes=TEST_CLASS_FOLDERS, class_mode='categorical', shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2025-12-12T10:02:42.114263Z","iopub.execute_input":"2025-12-12T10:02:42.114492Z","iopub.status.idle":"2025-12-12T10:02:43.341808Z","shell.execute_reply.started":"2025-12-12T10:02:42.114468Z","shell.execute_reply":"2025-12-12T10:02:43.341254Z"},"trusted":true},"outputs":[{"name":"stdout","text":"--- Initializing Data Generators ---\nFound 3770 images belonging to 5 classes.\nFound 941 images belonging to 5 classes.\nFound 250 images belonging to 5 classes.\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# --- MODEL BUILDING (VGG16 FINE TUNING) ---\nprint(\"\\n--- Building VGG16 Model ---\")\n\nbase_model = VGG16(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n)\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nfor layer in base_model.layers[-4:]:\n    layer.trainable = True\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(512, activation='relu')(x)\nx = BatchNormalization() (x)  \nx = Dropout(0.5)(x)          \npredictions = Dense(NUM_CLASSES, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2025-12-12T10:02:43.342654Z","iopub.execute_input":"2025-12-12T10:02:43.342887Z","iopub.status.idle":"2025-12-12T10:02:43.631003Z","shell.execute_reply.started":"2025-12-12T10:02:43.342870Z","shell.execute_reply":"2025-12-12T10:02:43.630177Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n--- Building VGG16 Model ---\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# 3. Compile Model\nmodel.compile(\n    optimizer=Adam(learning_rate=0.00001), \n    loss='categorical_crossentropy', \n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2025-12-12T10:02:43.633048Z","iopub.execute_input":"2025-12-12T10:02:43.633288Z","iopub.status.idle":"2025-12-12T10:02:43.641100Z","shell.execute_reply.started":"2025-12-12T10:02:43.633270Z","shell.execute_reply":"2025-12-12T10:02:43.640518Z"},"trusted":true},"outputs":[],"execution_count":44},{"cell_type":"code","source":"optimizer = Adam(learning_rate=0.0001)\n\nmodel.compile(\n    optimizer=optimizer,\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\ncheckpoint = ModelCheckpoint(\n    'best_wheat_model.keras',     \n    monitor='val_accuracy', \n    save_best_only=True, \n    mode='max', \n    verbose=1\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss', \n    factor=0.2,       \n    patience=3, \n    min_lr=1e-6,      \n    verbose=1\n)\n\nearly_stop = EarlyStopping(\n    monitor='val_loss', \n    patience=10,      \n    restore_best_weights=True,\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2025-12-12T10:02:43.641820Z","iopub.execute_input":"2025-12-12T10:02:43.642013Z","iopub.status.idle":"2025-12-12T10:02:43.652108Z","shell.execute_reply.started":"2025-12-12T10:02:43.641998Z","shell.execute_reply":"2025-12-12T10:02:43.651380Z"},"trusted":true},"outputs":[],"execution_count":45},{"cell_type":"code","source":"print(\"\\n--- Starting Training ---\")\nstart_time = time.time()\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // BATCH_SIZE,\n    callbacks=[checkpoint, reduce_lr, early_stop], \n    verbose=1\n)\n\ntraining_time = time.time() - start_time","metadata":{"execution":{"iopub.status.busy":"2025-12-12T10:02:43.652937Z","iopub.execute_input":"2025-12-12T10:02:43.653227Z","iopub.status.idle":"2025-12-12T10:27:53.251716Z","shell.execute_reply.started":"2025-12-12T10:02:43.653204Z","shell.execute_reply":"2025-12-12T10:27:53.250760Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n--- Starting Training ---\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - accuracy: 0.5064 - loss: 1.3636\nEpoch 1: val_accuracy improved from -inf to 0.51616, saving model to best_wheat_model.keras\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 731ms/step - accuracy: 0.5071 - loss: 1.3617 - val_accuracy: 0.5162 - val_loss: 1.2235 - learning_rate: 1.0000e-04\nEpoch 2/30\n\u001b[1m  1/117\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 200ms/step - accuracy: 0.6875 - loss: 1.0073","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2: val_accuracy did not improve from 0.51616\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 143ms/step - accuracy: 0.6875 - loss: 1.0073 - val_accuracy: 0.5119 - val_loss: 1.2097 - learning_rate: 1.0000e-04\nEpoch 3/30\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step - accuracy: 0.7260 - loss: 0.7724\nEpoch 3: val_accuracy improved from 0.51616 to 0.59806, saving model to best_wheat_model.keras\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 707ms/step - accuracy: 0.7260 - loss: 0.7724 - val_accuracy: 0.5981 - val_loss: 0.9747 - learning_rate: 1.0000e-04\nEpoch 4/30\n\u001b[1m  1/117\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 204ms/step - accuracy: 0.8125 - loss: 0.5450\nEpoch 4: val_accuracy improved from 0.59806 to 0.60129, saving model to best_wheat_model.keras\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 152ms/step - accuracy: 0.8125 - loss: 0.5450 - val_accuracy: 0.6013 - val_loss: 0.9745 - learning_rate: 1.0000e-04\nEpoch 5/30\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566ms/step - accuracy: 0.7721 - loss: 0.6551\nEpoch 5: val_accuracy improved from 0.60129 to 0.72522, saving model to best_wheat_model.keras\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 715ms/step - accuracy: 0.7721 - loss: 0.6550 - val_accuracy: 0.7252 - val_loss: 0.7017 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m  1/117\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 205ms/step - accuracy: 0.6875 - loss: 0.7939\nEpoch 6: val_accuracy did not improve from 0.72522\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 145ms/step - accuracy: 0.6875 - loss: 0.7939 - val_accuracy: 0.7004 - val_loss: 0.7644 - learning_rate: 1.0000e-04\nEpoch 7/30\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.7991 - loss: 0.5628\nEpoch 7: val_accuracy did not improve from 0.72522\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 706ms/step - accuracy: 0.7991 - loss: 0.5627 - val_accuracy: 0.7069 - val_loss: 0.7735 - learning_rate: 1.0000e-04\nEpoch 8/30\n\u001b[1m  1/117\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 206ms/step - accuracy: 0.8750 - loss: 0.3760\nEpoch 8: val_accuracy did not improve from 0.72522\n\nEpoch 8: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 141ms/step - accuracy: 0.8750 - loss: 0.3760 - val_accuracy: 0.7112 - val_loss: 0.7656 - learning_rate: 1.0000e-04\nEpoch 9/30\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.8423 - loss: 0.4552\nEpoch 9: val_accuracy improved from 0.72522 to 0.81466, saving model to best_wheat_model.keras\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 711ms/step - accuracy: 0.8424 - loss: 0.4550 - val_accuracy: 0.8147 - val_loss: 0.5349 - learning_rate: 2.0000e-05\nEpoch 10/30\n\u001b[1m  1/117\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 203ms/step - accuracy: 0.9375 - loss: 0.2456\nEpoch 10: val_accuracy did not improve from 0.81466\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 145ms/step - accuracy: 0.9375 - loss: 0.2456 - val_accuracy: 0.8093 - val_loss: 0.5384 - learning_rate: 2.0000e-05\nEpoch 11/30\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.8719 - loss: 0.3561\nEpoch 11: val_accuracy did not improve from 0.81466\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 712ms/step - accuracy: 0.8720 - loss: 0.3561 - val_accuracy: 0.8006 - val_loss: 0.5426 - learning_rate: 2.0000e-05\nEpoch 12/30\n\u001b[1m  1/117\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 211ms/step - accuracy: 0.7812 - loss: 0.5036\nEpoch 12: val_accuracy did not improve from 0.81466\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 145ms/step - accuracy: 0.7812 - loss: 0.5036 - val_accuracy: 0.8028 - val_loss: 0.5276 - learning_rate: 2.0000e-05\nEpoch 13/30\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.8811 - loss: 0.3338\nEpoch 13: val_accuracy improved from 0.81466 to 0.82004, saving model to best_wheat_model.keras\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 714ms/step - accuracy: 0.8811 - loss: 0.3339 - val_accuracy: 0.8200 - val_loss: 0.4847 - learning_rate: 2.0000e-05\nEpoch 14/30\n\u001b[1m  1/117\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 206ms/step - accuracy: 0.9375 - loss: 0.2090\nEpoch 14: val_accuracy did not improve from 0.82004\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 142ms/step - accuracy: 0.9375 - loss: 0.2090 - val_accuracy: 0.8157 - val_loss: 0.5336 - learning_rate: 2.0000e-05\nEpoch 15/30\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step - accuracy: 0.8791 - loss: 0.3342\nEpoch 15: val_accuracy improved from 0.82004 to 0.83190, saving model to best_wheat_model.keras\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 715ms/step - accuracy: 0.8791 - loss: 0.3341 - val_accuracy: 0.8319 - val_loss: 0.5006 - learning_rate: 2.0000e-05\nEpoch 16/30\n\u001b[1m  1/117\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 207ms/step - accuracy: 0.7188 - loss: 0.7426\nEpoch 16: val_accuracy did not improve from 0.83190\n\nEpoch 16: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.7188 - loss: 0.7426 - val_accuracy: 0.8211 - val_loss: 0.4939 - learning_rate: 2.0000e-05\nEpoch 17/30\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566ms/step - accuracy: 0.9047 - loss: 0.2766\nEpoch 17: val_accuracy improved from 0.83190 to 0.84375, saving model to best_wheat_model.keras\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 716ms/step - accuracy: 0.9047 - loss: 0.2767 - val_accuracy: 0.8438 - val_loss: 0.4658 - learning_rate: 4.0000e-06\nEpoch 18/30\n\u001b[1m  1/117\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 203ms/step - accuracy: 0.9688 - loss: 0.1447\nEpoch 18: val_accuracy improved from 0.84375 to 0.85345, saving model to best_wheat_model.keras\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 150ms/step - accuracy: 0.9688 - loss: 0.1447 - val_accuracy: 0.8534 - val_loss: 0.4621 - learning_rate: 4.0000e-06\nEpoch 19/30\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567ms/step - accuracy: 0.9092 - loss: 0.2686\nEpoch 19: val_accuracy did not improve from 0.85345\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 715ms/step - accuracy: 0.9091 - loss: 0.2687 - val_accuracy: 0.8491 - val_loss: 0.4716 - learning_rate: 4.0000e-06\nEpoch 20/30\n\u001b[1m  1/117\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 211ms/step - accuracy: 0.8750 - loss: 0.3614\nEpoch 20: val_accuracy did not improve from 0.85345\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 142ms/step - accuracy: 0.8750 - loss: 0.3614 - val_accuracy: 0.8459 - val_loss: 0.4635 - learning_rate: 4.0000e-06\nEpoch 21/30\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.9109 - loss: 0.2622\nEpoch 21: val_accuracy did not improve from 0.85345\n\nEpoch 21: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 705ms/step - accuracy: 0.9109 - loss: 0.2622 - val_accuracy: 0.8265 - val_loss: 0.4809 - learning_rate: 4.0000e-06\nEpoch 22/30\n\u001b[1m  1/117\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 206ms/step - accuracy: 0.9062 - loss: 0.2917\nEpoch 22: val_accuracy did not improve from 0.85345\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 142ms/step - accuracy: 0.9062 - loss: 0.2917 - val_accuracy: 0.8427 - val_loss: 0.4759 - learning_rate: 1.0000e-06\nEpoch 23/30\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560ms/step - accuracy: 0.9049 - loss: 0.2631\nEpoch 23: val_accuracy did not improve from 0.85345\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 703ms/step - accuracy: 0.9050 - loss: 0.2631 - val_accuracy: 0.8405 - val_loss: 0.4953 - learning_rate: 1.0000e-06\nEpoch 24/30\n\u001b[1m  1/117\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 209ms/step - accuracy: 0.9062 - loss: 0.1682\nEpoch 24: val_accuracy did not improve from 0.85345\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.9062 - loss: 0.1682 - val_accuracy: 0.8459 - val_loss: 0.4637 - learning_rate: 1.0000e-06\nEpoch 25/30\n\u001b[1m113/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 565ms/step - accuracy: 0.9034 - loss: 0.2899\nEpoch 25: val_accuracy improved from 0.85345 to 0.85560, saving model to best_wheat_model.keras\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 710ms/step - accuracy: 0.9033 - loss: 0.2898 - val_accuracy: 0.8556 - val_loss: 0.4653 - learning_rate: 1.0000e-06\nEpoch 26/30\n\u001b[1m  1/117\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 202ms/step - accuracy: 0.7812 - loss: 0.3661\nEpoch 26: val_accuracy did not improve from 0.85560\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 141ms/step - accuracy: 0.7812 - loss: 0.3661 - val_accuracy: 0.8448 - val_loss: 0.4558 - learning_rate: 1.0000e-06\nEpoch 27/30\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553ms/step - accuracy: 0.9098 - loss: 0.2470\nEpoch 27: val_accuracy improved from 0.85560 to 0.86207, saving model to best_wheat_model.keras\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 704ms/step - accuracy: 0.9098 - loss: 0.2471 - val_accuracy: 0.8621 - val_loss: 0.4566 - learning_rate: 1.0000e-06\nEpoch 28/30\n\u001b[1m  1/117\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 201ms/step - accuracy: 0.9375 - loss: 0.2653\nEpoch 28: val_accuracy did not improve from 0.86207\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 152ms/step - accuracy: 0.9375 - loss: 0.2653 - val_accuracy: 0.8427 - val_loss: 0.4729 - learning_rate: 1.0000e-06\nEpoch 29/30\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step - accuracy: 0.9222 - loss: 0.2447\nEpoch 29: val_accuracy did not improve from 0.86207\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 700ms/step - accuracy: 0.9222 - loss: 0.2447 - val_accuracy: 0.8470 - val_loss: 0.4809 - learning_rate: 1.0000e-06\nEpoch 30/30\n\u001b[1m  1/117\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9062 - loss: 0.2670\nEpoch 30: val_accuracy did not improve from 0.86207\n\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.9062 - loss: 0.2670 - val_accuracy: 0.8394 - val_loss: 0.4710 - learning_rate: 1.0000e-06\nRestoring model weights from the end of the best epoch: 26.\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"#EVALUATION \nprint(f\"\\n--- FINAL EVALUATION ---\")\n\nloss, accuracy = model.evaluate(test_generator, steps=test_generator.n // BATCH_SIZE + 1)\nprint(f\"Test Accuracy: {accuracy:.4f}\")\nprint(f\"Training Time: {training_time:.2f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2025-12-12T10:27:53.252681Z","iopub.execute_input":"2025-12-12T10:27:53.253423Z","iopub.status.idle":"2025-12-12T10:27:56.592786Z","shell.execute_reply.started":"2025-12-12T10:27:53.253401Z","shell.execute_reply":"2025-12-12T10:27:56.592179Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n--- FINAL EVALUATION ---\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 322ms/step - accuracy: 0.8779 - loss: 0.3945\nTest Accuracy: 0.9040\nTraining Time: 1509.59 seconds\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"# Classification Report\ntest_generator.reset()\nY_pred = model.predict(test_generator)\ny_pred = np.argmax(Y_pred, axis=1)\ny_true = test_generator.classes\n\nreport = classification_report(\n    y_true, \n    y_pred, \n    target_names=REPORT_TARGET_CLASSES, \n    zero_division=0,\n    output_dict=True \n)\n\nprint(\"\\n--- CLASSIFICATION REPORT ---\")\nprint(classification_report(y_true, y_pred, target_names=REPORT_TARGET_CLASSES, zero_division=0))","metadata":{"execution":{"iopub.status.busy":"2025-12-12T10:27:56.593511Z","iopub.execute_input":"2025-12-12T10:27:56.593801Z","iopub.status.idle":"2025-12-12T10:28:00.299784Z","shell.execute_reply.started":"2025-12-12T10:27:56.593773Z","shell.execute_reply":"2025-12-12T10:28:00.299009Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 288ms/step\n\n--- CLASSIFICATION REPORT ---\n                precision    recall  f1-score   support\n\n         Aphid       0.93      0.82      0.87        50\n   Wheat Blast       0.94      0.96      0.95        50\nPowdery Mildew       0.91      0.86      0.89        50\n          Smut       0.98      1.00      0.99        50\n   Spot Blotch       0.77      0.88      0.82        50\n\n      accuracy                           0.90       250\n     macro avg       0.91      0.90      0.90       250\n  weighted avg       0.91      0.90      0.90       250\n\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"model_name = \"VGG19\"\n\nmetrics_summary = {\n    'Model': model_name,\n    'Accuracy': report['accuracy'],\n    'Precision': report['weighted avg']['precision'], \n    'Recall': report['weighted avg']['recall'],\n    'F1-Score': report['weighted avg']['f1-score'],\n    'Training Time (s)': training_time,\n}\n\ndf_metrics = pd.DataFrame([metrics_summary])","metadata":{"execution":{"iopub.status.busy":"2025-12-12T10:28:00.300731Z","iopub.execute_input":"2025-12-12T10:28:00.301206Z","iopub.status.idle":"2025-12-12T10:28:00.306320Z","shell.execute_reply.started":"2025-12-12T10:28:00.301175Z","shell.execute_reply":"2025-12-12T10:28:00.305468Z"},"trusted":true},"outputs":[],"execution_count":49},{"cell_type":"code","source":"results_file = 'model_performance_summary.csv'\nif not os.path.exists(results_file):\n    df_metrics.to_csv(results_file, index=False)\nelse:\n    df_metrics.to_csv(results_file, mode='a', header=False, index=False)\n    \nprint(f\"\\nMetrics saved to {results_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T10:28:00.307088Z","iopub.execute_input":"2025-12-12T10:28:00.307286Z","iopub.status.idle":"2025-12-12T10:28:00.318939Z","shell.execute_reply.started":"2025-12-12T10:28:00.307271Z","shell.execute_reply":"2025-12-12T10:28:00.318223Z"}},"outputs":[{"name":"stdout","text":"\nMetrics saved to model_performance_summary.csv\n","output_type":"stream"}],"execution_count":50}]}